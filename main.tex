\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{fancyhdr}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{blindtext}
\usepackage[margin=1in,footskip=0.25in]{geometry}
\usepackage[most]{tcolorbox}
\usepackage[dvipsnames]{xcolor}

% if you ever want to ente% Required for inserting images

\title{Analysis Notes 131AH}
\author{OMKAR TASGAONKAR}
\date{Winter Quarter - January-March 2026}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}{Lemma}[section]
\newtheorem{defn}{Definition}[section]
\newtheorem{cor}{Corollary}[section]
\newtheorem{axm}{Axiom}[section]

\tcolorboxenvironment{thm}{
  colback=lime,
  colframe=black,
  breakable
}

\tcolorboxenvironment{lem}{
  colback=yellow,
  colframe=black,
  breakable
}

\tcolorboxenvironment{defn}{
  colback=pink,
  colframe=black,
  breakable
}

\tcolorboxenvironment{cor}{
  colback=SpringGreen,
  colframe=black,
  breakable
}

\tcolorboxenvironment{axm}{
  colback=white,
  colframe=black,
  breakable
}

\setlength{\parindent}{0pt}

\begin{document}

\maketitle
\section*{If you are reading this...}
Hello! These are my notes for analysis, which I have typed up to save to github so I can reference them in the future. Things will be written in my own words and may not be fully correct, but this is just my attempt to fully internalize everything and write it down as precisely as possible.
\tableofcontents
\pagebreak

\section{Propositional and First-Order Logic}
\begin{defn}
    A proposition is a statement that takes a TRUE or FALSE value
\end{defn}
For example, "birds are mammals" is a valid proposition, which takes on the value of FALSE. We also define a "primitive proposition", which is one with no connectives or quantifiers.\\

\begin{defn}
    A connective is a unary or binary operator allowing us to chain propositions to create new propositions
\end{defn}
The connectives we will work with are $\lnot$ (logical not), $\land$ (and), $\lor$ (or), $\implies$ (implies), and $\iff$ (bioconditional). The $\lnot$ operator is the only unary operator, which switches the value of the proposition. The others are binary, requiring two propositions and outputting one value.\\

We view an interesting truth table for $\implies$:
\begin{center}
\begin{tabular}{| c | c  | c |}
\hline
$P$ & $Q$ & $P \implies Q$ \\
\hline
T & T & T\\
T & F & F\\
F & T & T\\
F & F & T\\
\hline
\end{tabular}
\end{center}

\indent When $P$ is false but $Q$ is true, the entire statement is "vacuously" true as the expected proposition $Q$ is true no matter $P$. When both are false, the proposition is true as well. So in general when $P$ is false, $P \implies Q$ is true.\\

\begin{lem}
    $(P \implies Q) \iff \lnot(P \land \lnot Q) \iff \lnot P \lor Q$
\end{lem}
Here the biconditional means that the propositions are equivalent. We can use the biconditional to represent when two statements imply each other or are logically the same.\\

This lemma highlights proof by contradiction, where we assume $P$ and $\lnot Q$ and we show some contradiction (or show that the proposition is false). Then the logical not of the proposition is true. The second equivalence is an application of DeMorgan's Laws for logic.\\

\begin{lem}
    $(P \implies Q) \iff \lnot Q \implies \lnot P$
\end{lem}
This is the method of proof by contrapositive. This implication is called the \textbf{"only if"} direction, while the reverse is the \textbf{"if"} direction.\\

\begin{defn}
    We propose two quantifiers: $\forall$ (for all/for each) and $\exists$ (there exists)
\end{defn}
A first order statement assumes the form: (quantifier)(variable): (proposition). This is the basis of First Order Logic, an extension of propositional logic. For example:
\begin{equation*}
    \forall x : P(x)
\end{equation*}
translates to: for all x such that $P(x)$ is true. The terminology "some" is equivalent to $\exists$.\\

\begin{lem}
    $\lnot(\forall x : P(x)) \iff \exists x : \lnot P(x)$ and $\lnot(\exists x: P(x)) \iff \forall x : \lnot P(x)$
\end{lem}
Here we see how the logical not operator distributes over quantifier and proposition.\\

\begin{thm}
    $\forall x \forall y: P(x, y) \iff \forall y, \forall x: P(x, y)$ and $\exists x, \exists y: P(x, y) \iff \exists y, \exists x: P(x, y)$
\end{thm}
If the quantifiers for two variables are the same, we can switch the order of the quantifiers. This will appear in proofs involving sets and supremums/infimums. However, if they are not the same, then we cannot suggest an equivalence.\\

\begin{thm}
    $\exists x \forall y: P(x, y) \implies \forall y \exists x: P(x, y)$
\end{thm}
The reason why this is a one-way implication is because the left hand statement is more specific. We will encounter this when dealing with images and preimages. We take the following example:\\

\textbf{Mathematical Example}: If there exists one $x$ greater than all $y$, then for each $y$ there exists an $x > y$. In this case that $x$ is the same. For the converse, if each $y$ has an $x > y$, there may not be a singular $x$ greater than all $y$.\\

\textbf{Figurative Example}: If there is one building to which all apartments belong, then all the apartments belong to that building. However, if all the apartments belong to \text{a} building, not necessarily they belong to one building. We can have the apartments in multiple buildings.
\pagebreak

%------------------------------------------------------------%

\section{Naive Set Theory and Zermelo Fraenkel}
\subsection{Naive Set Theory}
Naive Set Theory was the initial proposed set theory. A set being a container for some sort of objects. To construct a set, we have the following:
\begin{defn}
    The Comprehension Principle: $A \coloneq \{x : P(x)\}$
\end{defn}
The symbol $\coloneq$ means "defined as". If we use "$=$" when referring to sets, that is not the same as using $\coloneq$.\\

The Comprehension Principle tells us that a set is some elements $x$ that satisfy a proposition $P(x)$. We won't dwell on this theory too much, but it has pitfalls such as Russell's paradox:
\begin{equation*}
    A \coloneq \{x : x \notin x\}
\end{equation*}

Here if $x \notin x$, then we could say $A \notin A$, but the proposition tells us that $A \in A$, so we come across a contradiction.\\

\subsection{Zermelo Fraenkel}
\begin{axm}
    \textbf{Axiom of Separation} Any set $A$ can be defined as $\{x \in U : P(x)\}$.
\end{axm}
We see that the elements $x \in A$ are being drawn from $U$ which in this case can be a universe (all the possible sets, but this is not itself a set), or a bigger set. By restricting elements, we can prevent self references such as those in Russell's paradox.\\

\begin{axm}
    \textbf{Axiom of Extensionality} $\forall A, B: A = B \iff \forall x: (x \in A \iff x \in B)$
\end{axm}
We mentioned previously that $\coloneq$ is not the same as $=$ for sets. Extensionality gives the definition of $=$ to be that the sets must have the same elements. The axiom itself is sometimes written as an implication rather than a biconditional.\\

\begin{axm}
    \textbf{Empty Set}: $\exists \varnothing : \forall x \in U: x \notin \varnothing$
\end{axm}
We postulate the existence of the empty set, which contains none of the possible elements in the universe. Now, how do we build the set of all subsets (aka the powerset)?\\

\begin{defn}
    $\subseteq$ (subset relation): $\forall A, B: A \subseteq B \implies \forall x \in A: x \in B$
\end{defn}
Let's try to use the Axiom of Separation and this definition to construct the powerset. We can say maybe for a set $A$ that $\mathcal{P}(A) \coloneq \{B \in C: B \subseteq A\}$. But this definition requires a set $C$ to exist in which $B$ belongs, so either this is the powerset or a set containing more elements than the powerset, and so we have a circular definition.\\

\begin{axm}
    \textbf{Powerset}: $\forall A \exists \mathcal{P}(A): (\forall B \subset A: B \in \mathcal(P)(A))$
\end{axm}
We have the same issue when we go to define a set such as $\{x, y\}$, which is called the pairset, as each element is also inherently a set.\\

\begin{axm}
    \textbf{Pairset}: $\forall x, y \exists A \forall Z \in A: x = z \lor y = z$
\end{axm}
The pairset allows us to show the existence of a singleton set $\{x\}$ if both the elements given are the same as $\{x, x\} = \{x\}$. This can be shown by extensionality.\\

\begin{axm}
    \textbf{Infinite Set}: $I \coloneq \{x: x \in I \implies \{x\} \in I\}$
\end{axm}
This is one possible construction of the infinite set we will use for the naturals; however, this axiom postulates the existence of infinite sets. Many of the constructions in analysis will hinge on this axiom; without it, we fail to construct the idea of "natural numbers" let alone "real numbers".\\
\pagebreak

%----------------------------------------------------------------------------%

\section{Ordered Pairs and Relations}
We talk about pairs (or n-tuples) of numbers such as $(1, 2)$ or $(x, y)$. However, we also distinguish the order unlike sets, saying that $(1, 2)$ is not the same as $(2, 1)$.\\

\begin{defn}
    \textbf{Kuratowski Pair}: $(x, y) \coloneq \{\{x\}, \{x, y\}\}$
\end{defn}
\pagebreak

%---------------------------------------------------------------------%
\section{Isomorphisms of Dedekind Cuts and Ordered Fields}
So far we have constructed the reals or $\mathbb{R}$ as the set of Dedekind cuts, which are the set of rationals less than that real number. By allowing for completeness, we can show that each cut admits an upper bound so it admits a supremum.\\

The supremum is the real number itself; however, quantifying the supremum will require the existence of an algebraic structure that encompasses the supremum. If we solely rely on $\mathbb{Q}$, then certain cuts may not admit supremums in $\mathbb{Q}$.\\

So we say there exists some complete ordered field $(F, +, 0, \cdot, 1, \leqslant)$ (completeness is important here, otherwise we cannot guarantee supremums). Each ordered field fundamentally has the $\mathbb{N}_F$. We examine a theorem:
\begin{thm}
    If $F$ is an ordered field, then it has characteristic $0$
\end{thm}
\noindent We prove this by contrapositive:
\begin{proof}
Assume $F$ does not have characteristic 0. Then $\sum_{k=1}^{n}(1) = 0$ for an arbitrary n. We then know that $0 < 1$, by ordered field properties:
\begin{equation*}
    0 < 1 \implies 0 < \sum_{k=1}^{n-1}(1) < \sum_{k=1}^{n-1}(1) + 1 = \sum_{k=1}^{n}(1)
\end{equation*}
Now assume the inequality to be true, then by mulitplicative property of ordered fields:
\begin{equation*}
    \implies \sum_{k=1}^{n-1}(1) \cdot \sum_{k=1}^{n-1}(1) < \sum_{k=1}^{n}(1) \cdot \sum_{k=1}^{n-1}(1)
\end{equation*}
\begin{eqnarray}
    \iff (n-1)^2 = n^2 - 2n + 1 < n(n-1) = n^2 - n
\end{eqnarray}
We know that $n$ or $1$ added $n$ times repeatedly is equal to zero, so we get:
\begin{equation*}
    0 + 1 = 1 < 0
\end{equation*}
Which is a contradiction of a key property of ordered fields that $0 \leqslant 1$. 
\end{proof}
\noindent So now, the addition of of $1$ to an element of the field becomes our sucessor operation, and $0$ becomes our zero element. If we then consider the subset of elements greater than zero, then zero is not a sucessor of any number in the set. Thus we can construct the naturals in a field as:
\begin{equation*}
    \mathbb{N}_F = \bigcap_{\alpha \in I}\{A_\alpha \subseteq F: (\forall x \in A_\alpha: x +1 \in A_\alpha)\}
\end{equation*}

\noindent Now that we have the naturals in every ordered field, by field properties, we require their additive and multiplicative inverses. Furthermore any combination of these must also remain in the field, giving rise to the rationals $\mathbb{Q}_F$ (considered the "minimal" ordered field).\\

\noindent So currently we have the set of Dedekind cuts $\mathbb{R}$ and an ordered field structure $F$. One is constructed from ground up, the other's existence is assumed respectively. We aim to show the two are isomorphic. We know the following theorem proved in prior chapters:
\begin{thm}
The rationals of different fields are isomorphic
\end{thm}
\noindent So there exists an isomorphism we call $\psi: \mathbb{Q} \xrightarrow{} \mathbb{Q}_F$. Since the Dedekind cuts are merely sets of rationals, then we can construct cuts in $F$ which we call $\mathbb{R}_F$. We can extend $\psi: \mathbb{R} \xrightarrow{} \mathbb{R}_F$.\\

\begin{thm}
    $\forall A \in \mathbb{R}_F: (\exists b \in F, \forall a \in A: a \leqslant b): \sup: A \xrightarrow{} F$ and $\sup$ is an isomorphism
\end{thm}
\noindent This lemma is essentially the restatement of the completeness of $F$. If we take any subset bounded above, then it admits a supremum. However, here we define the supremum as a map from a set to an element in the field. We prove it is an isomorphism for a cut specifically. We require the lemma:
\begin{lem}
    $\forall A \in \mathbb{R}_F: A = \{a \in \mathbb{Q}_F: a < \sup(A)\}$
\end{lem}
\noindent For now we only show the inclusion $A \subseteq \{a \in \mathbb{Q}_F: a < \sup(A)\}$.
\begin{proof}
If $x \in A$, then $x \leqslant \sup(A)$. If $x = \sup(A) \implies \sup(A) \in A$. By the definition of Dedekind cut's, there cannot be a maximal element, so:
\begin{equation*}
    \exists b \in A: \sup(A) < b \land b \leqslant \sup(A)
\end{equation*}
The second inequality comes from the supremum definition. We see that we get a contradiction, so $\sup(A) \notin A$, thus $\forall a \in A: a < \sup(A)$.
\end{proof}

\noindent We now return to proving the theorem at hand.
\begin{proof}
For the sake of brevity we assume $\sup$ is a homomorphism (which means that it respects the operations of sets and the field). We aim to show injectivity:
\begin{equation*}
    \forall A, B: \sup(A) = \sup(B) \implies A = B
\end{equation*}
If two cuts are not equal, then either $A \subset B \lor B \subset A$. Assume without loss of generality that $A \subset B$. Then:
\begin{equation*}
    \exists b \in B, \forall a \in A: a < b
\end{equation*}
This inequality we can derive from the ordering of $F$ and the construction of the cuts. Then $b$ is an upper bound for $A$ and by definition of supremum $\sup(A) \leqslant b$. So by the lemma $a < \sup(A) \leqslant b < \sup(B)$. Thus $\sup(A) < \sup(B)$, proving injectivity of $\sup$.
\end{proof}

\begin{proof}
We now prove the surjectivity of $\sup$:
\begin{equation*}
    \forall x \in F, \exists A \in \mathbb{R}_F: \sup(A) = x
\end{equation*}
Assume for a certain $x \in F$, that there does not exist an $A \in \mathbb{R}_F$ such that $\sup(A) = x$. Then all Dedekind cuts must admit a supremum in $F$ as they are bounded above. (The following part may be a bit hand wavy :), but in essence by means of pigeonhole principle (whose proof we detailed before), two different cuts will then share the same supremum, which breaks injectivity. 
\end{proof}

\medskip
\begin{thm}
For all complete ordered fields $(F, +, 0, \cdot, 1, \leqslant)$, we find that $\mathbb{R} \cong F$.
\end{thm}
The proof of this is simply a combination of the previous theorems and lemmas. We know that $\psi: \mathbb{R} \xrightarrow{} \mathbb{R}_F$ is an isomorphism and $\sup: \mathbb{R}_F \xrightarrow{} F$ is also an isomorphism. The composition is therefore an isomorphism:
\begin{equation*}
    \sup \circ \psi: \mathbb{R} \xrightarrow{} F
\end{equation*}
So the Dedekind cut representation of the reals are isomorphic to any complete ordered field. So now instead of dealing with the reals as a set of Dedekind cuts, we can deal with it as an ordered field of the supremums of the Dedekind cuts. So $\sqrt{2}$ is a supremum of the cut, so we can explicitly refer to the cut as $\sqrt{2}$ itself even though the cut does not admit a supremum in $\mathbb{Q}$. 
\pagebreak

%----------------------------------------------------------------------------------%

\section{Properties of the Reals}
We have determined that every complete ordered field is isomorphic to the real numbers. We now aim to show certain properties have correctly carried forward to this construction.\\

We dealt with rational roots and equalities such as $x^2 = 2$ that did not admit solutions in the rationals, but allowed us to construct $\sqrt{2}$ in the reals. We now see the reals hold for arbitrary roots as well:
\begin{thm}
$\forall a \in \mathbb{R}^+, \forall n \in \mathbb{N}\setminus \{0\}: (\exists x \in \mathbb{R}^+: x^n = a) \land (x^n = y^n \implies x = y)$
\end{thm}
In essence, there exists an $nth$ root for every real number, which is unique. We use the following property:
\begin{equation*}
    \forall x, y \in \mathbb{R}, \forall n \in \mathbb{N}\setminus \{0\}: x^n - y^n = (x-y)\sum_{k=0}^{n-1}x^k y^{n-k-1}
\end{equation*}
Integer exponentiation can be defined by field properties as repeated multiplication of the element in the field.\\

\textbf{HW 5 Problem}: We prove the property below:
\begin{proof}
By the distributive property of multiplication in fields:
\begin{equation*}
    (x-y)\sum_{k=0}^{n-1}x^k y^{n-k-1} = x\sum_{k=0}^{n-1}x^k y^{n-k-1} - y\sum_{k=0}^{n-1}x^k y^{n-k-1}
\end{equation*}
\begin{equation*}
    = \sum_{k=0}^{n-1}x^{k+1} y^{n-k-1} - \sum_{k=0}^{n-1}x^k y^{n-k}
\end{equation*}
We can notice a pattern of cancellations here. The last term of the left term is $x^n$ and the first term of the right term is $y^n$. We can then rewrite the sum as:
\begin{equation*}
    = x^n - y^n + \sum_{k=0}^{n-2}x^{k+1} y^{n-k-1} - \sum_{k=1}^{n-1}x^k y^{n-k}
\end{equation*}
We see that the two summations output the same terms, just that the starting and ending indices are up by 1. If our starting term is $x y^{n-1}$, then at $k=0$ we sum $x^{k+1}y^{n-k-1}$, but at $k=1$, we sum $x^k y^{n-k}$.\\

If our last term is $x^{n-1}y$, then the same applies. So the two summations are equal, thus their subtraction equals 0, and our resultant expression is $x^n - y^n$.
\end{proof}

\medskip
We return to the proof of the theorem. We define the set $A \coloneq \{y \in \mathbb{R}^+: y^n \leqslant a\}$. Since this is a subset of the field, if it is bounded, then it admits a supremum:
\begin{equation*}
    1 + a > a \implies (1 + a)^n > (1+a)^{n-1}a > a^n > a \ \ (\text{Ordering Property of Multiplication})
\end{equation*}
Thus $\forall y \in A: y \leqslant 1 + a$ so $A$ is bounded above, thus it admits a supremum. We want to show that $\sup(A)^n = a$, thus defining the supremum of the set as the n-th root and showing its existence (as we know supremum exists).
\begin{proof}
We use the fact that $\forall y \in A: y \leqslant \sup(A)$, We first show $\sup(A)^n \leqslant A$. We also use the fact that:
\begin{equation*}
    \forall m \in \mathbb{N}\setminus \{0\}: \sup(A) - \frac{1}{m} < \sup(A) \implies \exists y \in A: \sup(A) - \frac{1}{m} \leqslant y
\end{equation*}
\begin{equation*}
    \sup(A)^n - a \leqslant \sup(A)^n - y^n = (\sup(A) - y)\sum_{k=0}^{n-1}\sup(A)^k y^{n-k-1}
\end{equation*}
Our previous implication that $\sup(A) - \frac{1}{m} \leqslant y \iff \sup(A) \leqslant y + \frac{1}{m} \implies \sup(A) \leqslant y$. Since $y \in A$, we know that $y \leqslant \sup(A)$, so $y = \sup(A)$. Our inequality becomes:
\begin{equation*}
    \sup(A)^n - a \leqslant \sup(A)^n - y^n = (\sup(A) - y)\sum_{k=0}^{n-1}\sup(A)^k y^{n-k-1} = 0 \iff \sup(A)^n \leqslant a
\end{equation*}

\medskip
We now prove that $\sup(A)^n \geqslant a$. We note that $\forall m \in \mathbb{N}\setminus \{0\}: \sup(A) + \frac{1}{m} > \sup(A)$, so:
\begin{equation*}
    (\sup(A) + \frac{1}{m})^n > a \implies a - \sup(A)^n < (\sup(A) + \frac{1}{m})^n - \sup(A)^n 
\end{equation*}
\begin{equation*}
    = \frac{1}{m}\sum_{k=0}^{n-1}(\sup(A)+\frac{1}{m})^k \sup(A)^{n-k-1} \leqslant \frac{n}{m}(\sup(A) + \frac{1}{m})^{n-1}
\end{equation*}
Thus, by dividing both sides (also the Archimedian Property is really a double implication), we see that:
\begin{equation*}
    \frac{m}{n}\frac{a - \sup(A)^n}{(\sup(A) + \frac{1}{m})^{n-1}} < 1 \implies a - \sup(A)^n \leqslant 0 \iff \sup(A)^n \geqslant a
\end{equation*}
So we have proven that $\sup(A)^n = a$, proving the existence of the $nth$ root, which we will denote by $a^{1/n}$.
\end{proof}

\medskip
\begin{proof}
We now prove the uniqueness of the $n-th$ root. Assume there are two $n-th$ roots of $a$ such that $y^n = a = \tilde{y}^n$. Then:
\begin{equation*}
    \sup(A)^n = y^n = \tilde{y}^n = a \implies a^{1/n} = \sup(A) = y = \tilde{y}
\end{equation*}
Since the supremum is unique, then if $y = \sup(A) = \tilde{y}$, then $y$ must equal $\tilde{y}$, so the $nth$ root is unique.
\end{proof}

\medskip
Now that we have the notion of natural powers and $nth$ roots, we can extend this to rational roots. We know that any rational can be represented as the ratio of two integers $p/q$. Note the following:
\begin{cor}
$\forall n \in \mathbb{N}, \forall a \in \mathbb{R}: a^{-n} = (a^{-1})^n = (\frac{1}{a})^n$
\end{cor}
With this corollary, we are able to define the notion of integer powers (as integers have additive inverses not accounted for by natural powers). Another property of natural powers and by extension integer powers:
\begin{cor}
$\forall m, n \in \mathbb{N}: a^m \cdot a^n = a^{m+n} \land a^{m \cdot n} = (a^m)^n$
\end{cor}

\medskip
\textbf{HW 5 Problem}: Using this corollary, we can prove the following lemma. For this problem assume $a > 1$:
\begin{lem}
$\forall m, n, p, q \in \mathbb{Z}: n, q > 0 \land \frac{m}{n} = \frac{p}{q} \implies \forall a > 1: (a^m)^{1/n} = (a^p)^{1/q}$
\end{lem}
\begin{proof}
If $\frac{m}{n} = \frac{p}{q}$, then we know that $mq = np$ where the two are integers. If $m/n < 0$, then $p/n < 0$ and same for $m/n \geqslant 0$. Thus the two fractions take on the same sign. Therefore $mq = np$ will either be positive or negative.\\

If $mq = np < 0$, we simply define their additive inverses $m'q' = n'p' > 0$ and use them to construct an equality (eg $-a = -b \iff a = b$ by field properties). So without loss of generality we proceed with $mq = np > 0$:
\begin{eqnarray}
    a^{mq} = a^{qm} = (a^q)^m \land a^{np} = a^{pn} = (a^p)^n
\end{eqnarray}
This is true by properties of exponentiation with respect to naturals and field multiplication. Thus, by the existence of arbitary roots:
\begin{equation*}
    (a^q)^m = (a^p)^n \implies ((a^q)^m)^{1/n} = a^p \implies ((a^m)^q)^{1/n} = a^p
\end{equation*}
We need to show that we can exchange the places of $q$ and $1/n$, so we prove $(a^m)^{1/n} = (a^{1/n})^m: n > 0$:
\begin{equation*}
    ((a^m)^{1/n})^n = a^m \land ((a^{1/n})^m)^n = (a^{1/n})^{mn} = (a^{1/n})^{nm} = ((a^{1/n})^n)^m = a^m
\end{equation*}
Since both expressions to raised to the $n: n > 0$ are equal, then the $nth$ roots are also equal so $(a^m)^{1/n} = (a^{1/n})^m$.\\

So returning to our initial statement:
\begin{equation*}
    ((a^m)^q)^{1/n}  = a^p \implies ((a^m)^{1/n})^{q} = a^p \implies (a^m)^{1/n} = (a^p)^{1/q}
\end{equation*}
\end{proof}
\begin{cor}
$\forall p, q \in \mathbb{Z}, q \neq 0: a^\frac{p}{q} = (a^p)^{1/q} = (a^{1/q})^p$
\end{cor}

\medskip
\begin{lem}
$\forall r, s \in \mathbb{Q}: a^{r+s} = a^r \cdot a^s$
\end{lem}
\begin{proof}
We let $r = \frac{m}{n}$ and $s = \frac{p}{q}$, where $m, n, p, q \in \mathbb{Z} \land p, q \neq 0$, then $r + s = \frac{m}{n} + \frac{p}{q} = \frac{mq + np}{pq}$. Thus by corollary 5.3:
\begin{equation*}
    a^{r+s} = a^{(mq + np)/pq} = (a^{1/pq})^{mq + np}
\end{equation*}
Now $mq + np$ is an integer expression, by corollary 5.2, we can rewrite the expression as:
\begin{equation*}
    = (a^{1/pq})^{mq} \cdot (a^{1/pq})^np = (a^{mq/pq}) \cdot (a^{np/pq}) = a^{m/p} \cdot a^{n/q} = a^r \cdot a^s
\end{equation*}
\end{proof}

\medskip
Now that we have defined and proven the properties of rational powers, we need to define real powers, which we do via supremums again leveraging completeness of the underlying ordered field:
\begin{defn}
$a^x \coloneq \begin{cases}
    \sup\{a^z: z \in \mathbb{Q} \land z \leqslant x\}, \ \ a > 1\\
    \inf\{a^z: z \in \mathbb{Q} \land z \leqslant x\}, \ \ a < 1\\
    1, \ \ a = 1\\
    1, \ \ \forall a \in \mathbb{R} \land x = 0
\end{cases}$
\end{defn}
\begin{proof}
We prove the first case, where if $a > 1$ then $a^x = \sup\{a^z: z \in \mathbb{Q} \land z \leqslant x\}$. We know that $x < x+1$. By density of the rationals:
\begin{equation*}
  \exists r \in \mathbb{Q}: x < r < x+1  
\end{equation*}
Since $z \leqslant q$, then $z < r$. We now need to prove the lemma:
\begin{lem}
$\forall z, r \in \mathbb{Q}: z < r \implies a^z < a^r$. 
\end{lem}
If $z < r$, then $a > 1 \implies a^{-1} < 1$ by field properties of multiplication and if $x \in F: x > 0$, then $x^{-1} > 0$ proved in previous homework:
\begin{equation*}
    a^{z-r} = (a^{-1})^{r-z} \land a^{-1} < 1 \implies (a^{-1})^{r-z} < 1^{r-z} = 1
\end{equation*}
\begin{equation*}
    \implies a^{z-r} < 1 \iff a^z \cdot a^{-r} < 1 \iff a^z \cdot (a^r)^{-1} < 1 \implies a^z < a^r
\end{equation*}
Once again we use the fact that $a > 1 \implies a^r > 1^r > 1 > 0 \implies (a^r)^{-1} > 0$ or that the inverse of a positive element is positive.\\

Therefore $a^z < a^r$, making $a^r$ an upper bound and allowing for the set to admit a supremum. We now want to show that $a^x$ is the least upper bound. Consider any upper bound $a^p: p \in \mathbb{Q}$, then:
\begin{equation*}
    \forall z \leqslant x: a^z \leqslant a^p \implies a^x \leqslant a^p
\end{equation*}
Then $a^z \leqslant a^p \iff a^p \geqslant a^z$ by the contrapositive of Lemma 5.3 implies that $p \geqslant z$ or $z \leqslant p$. Thus $a^p$ is an upper bound...(not sure what to do after this)

\medskip
\begin{lem}
  $\forall x, y \in \mathbb{R}: a^{x+y} = a^x \cdot a^y$  
\end{lem}
We define $a^{x+y} = \sup\{a^z: z \in \mathbb{Q} \land z \leqslant x + y\}$.\\

Since $a^y = \sup\{a^p: p \in \mathbb{Q} \land p \leqslant y\}$ and $a^x = \sup\{a^q: q \in \mathbb{Q} \land q \leqslant x\}$:
\begin{equation*}
    a^x \cdot a^y = \sup\{a^q\} \cdot \sup\{a^p\} = \sup\{a^q \cdot a^p\} = \sup\{a^{q+p}\}
\end{equation*}
This follows from Lemma 5.2 and $\sup$ being a homomorphism. Multiplying the supremums combines the predicates in a logical $\land$ and results in a Minkowski product. By ordered field properties:
\begin{equation*}
    q \leqslant x \land p \leqslant y \implies q + p \leqslant x + y
\end{equation*}
By definition of the set of $a^{x+y}$, we see $\forall q \leqslant x, \forall p \leqslant y: a^{p+q} \in \{a^z: z \leqslant x + y\}$. Therefore:
\begin{equation*}
    \{a^{q+p}\} \subseteq \{a^z\} \implies \sup\{a^{q+p}\} \leqslant \sup\{a^z\} \iff a^x \cdot a^y \leqslant a^{x+y}
\end{equation*}
Thus $a^x \cdot a^y = \sup\{a^{q+p}: p \leqslant y \land q \leqslant x\} \leqslant \sup\{a^{z}: z \leqslant x + y\}  = a^{x+y}$. \\

We now prove the opposite inequality, that $a^{x+y} \leqslant a^x \cdot a^y$. We choose a fixed $\tilde{q} \leqslant x$ and a fixed $\tilde{p} \leqslant y$, then:
\begin{equation*}
    a^{x+y} = \sup\{a^{z}: z \leqslant x + y\}
\end{equation*}
For every z, we can pick $\tilde{p}, \tilde{q}$ such that:
\begin{equation*}
    \forall z \leqslant x + y: \exists \tilde{p}, \tilde{q}: z \leqslant \tilde{p} + \tilde{q} \leqslant x + \tilde{p} \leqslant x + y
\end{equation*}
Thus $a^z \leqslant a^{\tilde{p} + \tilde{q}}$ by lemma 5.3, which means that since the choices of $\tilde{p}, \tilde{q}$ were arbitrary:
\begin{equation*}
    a^{x+y} = \sup\{a^z: z \leqslant x + y\} \leqslant \sup\{a^{q+p}: q \leqslant x \land p \leqslant y\} = a^x \cdot a^y
\end{equation*}
Thus proving $a^{x+y} = a^x \cdot a^y$.
\end{proof}
\end{document}
